"""
Real-Time Intelligence Engine Î³Î¹Î± ÏˆÎ·Ï†Î¹Î±ÎºÏŒ Î´Î¯Î´Ï…Î¼Î¿ Î´Î¹Î±Î²Î®Ï„Î·.

Î ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹:
- Edge inference Î³Î¹Î± wearable devices
- Federated learning Î³Î¹Î± privacy-preserving training
- Digital biomarker discovery ÎºÎ±Î¹ monitoring
- Clinical decision support system
- Causal inference Î³Î¹Î± treatment optimization
- Personalized adaptive control
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import asyncio
import threading
from typing import Dict, List, Optional, Tuple, Callable, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings("ignore")

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import fedml

    FEDML_AVAILABLE = True
except ImportError:
    FEDML_AVAILABLE = False

try:
    from causalnex.structure import StructureModel
    from causalnex.inference import InferenceEngine

    CAUSAL_INFERENCE_AVAILABLE = True
except ImportError:
    CAUSAL_INFERENCE_AVAILABLE = False


@dataclass
class GlucoseAlert:
    """Î•Î¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î³Î¹Î± Î³Î»Ï…ÎºÏŒÎ¶Î·."""

    timestamp: datetime
    glucose_value: float
    predicted_value: float
    alert_type: str  # 'hypoglycemia', 'hyperglycemia', 'rapid_change'
    severity: str  # 'low', 'medium', 'high', 'critical'
    recommendation: str
    confidence: float


@dataclass
class DigitalBiomarker:
    """Î¨Î·Ï†Î¹Î±ÎºÏŒÏ‚ Î²Î¹Î¿Î´ÎµÎ¯ÎºÏ„Î·Ï‚."""

    name: str
    value: float
    timestamp: datetime
    trend: str  # 'increasing', 'decreasing', 'stable'
    percentile: float  # Î£Îµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ population
    clinical_significance: str


class EdgeInferenceEngine:
    """
    Optimized inference engine Î³Î¹Î± edge devices (smartwatches, CGM devices).

    Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ quantized models ÎºÎ±Î¹ efficient architectures Î³Î¹Î±
    real-time inference Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· ÎºÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±Ï‚.
    """

    def __init__(
        self,
        model_path: str,
        quantization: bool = True,
        max_latency_ms: float = 100.0,
        battery_optimization: bool = True,
    ):

        self.model_path = model_path
        self.quantization = quantization
        self.max_latency_ms = max_latency_ms
        self.battery_optimization = battery_optimization

        self.model = None
        self.preprocessor = None
        self.last_inference_time = None
        self.inference_stats = {"total_inferences": 0, "avg_latency_ms": 0, "battery_usage": 0}

    def load_model(self):
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ optimization Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î³Î¹Î± edge deployment."""

        # Load model
        checkpoint = torch.load(self.model_path, map_location="cpu")
        self.model = checkpoint["model"]

        # Quantization Î³Î¹Î± Î¼ÎµÎ¯Ï‰ÏƒÎ· Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ ÎºÎ±Î¹ Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
        if self.quantization:
            self.model = torch.quantization.quantize_dynamic(
                self.model, {nn.Linear}, dtype=torch.qint8
            )

        # Optimization Î³Î¹Î± inference
        self.model.eval()
        if hasattr(self.model, "fuse_model"):
            self.model.fuse_model()

        # JIT compilation Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
        if hasattr(torch, "jit"):
            dummy_input = torch.randn(1, 10)  # Adjust based on model
            self.model = torch.jit.trace(self.model, dummy_input)

        print(f"âœ… Edge model loaded and optimized")

    def predict_glucose(
        self,
        cgm_readings: List[float],
        additional_data: Optional[Dict] = None,
        return_confidence: bool = True,
    ) -> Tuple[float, float]:
        """
        Ultra-fast glucose prediction Î³Î¹Î± edge devices.

        Returns:
            Tuple of (predicted_glucose, confidence)
        """
        start_time = datetime.now()

        # Preprocessing (lightweight)
        input_tensor = torch.tensor(cgm_readings[-10:], dtype=torch.float32).unsqueeze(0)

        # Inference
        with torch.no_grad():
            if self.battery_optimization:
                # Adaptive precision based on battery level
                with torch.autocast("cpu"):
                    prediction = self.model(input_tensor)
            else:
                prediction = self.model(input_tensor)

        # Extract prediction and confidence
        glucose_pred = prediction[0].item()
        confidence = prediction[1].item() if prediction.shape[1] > 1 else 0.95

        # Update stats
        latency = (datetime.now() - start_time).total_seconds() * 1000
        self.inference_stats["total_inferences"] += 1
        self.inference_stats["avg_latency_ms"] = (
            self.inference_stats["avg_latency_ms"] * (self.inference_stats["total_inferences"] - 1)
            + latency
        ) / self.inference_stats["total_inferences"]

        if latency > self.max_latency_ms:
            print(f"âš ï¸ Latency warning: {latency:.1f}ms > {self.max_latency_ms}ms")

        return glucose_pred, confidence

    def adaptive_sampling(self, current_glucose: float, trend: str) -> int:
        """
        Adaptive sampling rate based on glucose level and trend.

        Returns:
            Sampling interval in seconds
        """
        if current_glucose < 70 or current_glucose > 180:
            return 60  # Every minute for dangerous levels
        elif trend in ["rapidly_increasing", "rapidly_decreasing"]:
            return 120  # Every 2 minutes for rapid changes
        else:
            return 300  # Every 5 minutes for normal levels


class FederatedLearningManager:
    """
    Federated Learning Î³Î¹Î± privacy-preserving model updates.

    Î•Ï€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î½Î± ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î­ÏÎ¿Ï…Î½ ÏƒÏ„Î· Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Î¼Î¿Î¹ÏÎ¬Î¶Î¿Î½Ï„Î±Î¹ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.
    """

    def __init__(
        self,
        client_id: str,
        server_url: str = "federated.digitaltwint1d.org",
        privacy_budget: float = 1.0,
        min_clients: int = 10,
    ):

        self.client_id = client_id
        self.server_url = server_url
        self.privacy_budget = privacy_budget
        self.min_clients = min_clients

        self.local_model = None
        self.global_model_version = 0
        self.contribution_score = 0.0

    def train_local_model(
        self, local_data: pd.DataFrame, epochs: int = 5, differential_privacy: bool = True
    ) -> Dict[str, Any]:
        """
        Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Ï„Î¿Ï€Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î¼Îµ differential privacy.

        Returns:
            Model updates Î³Î¹Î± Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® ÏƒÏ„Î¿Î½ server
        """
        if not FEDML_AVAILABLE:
            print("âš ï¸ FedML not available. Simulating federated learning...")

        # Simulate local training with privacy
        if differential_privacy:
            # Add noise Î³Î¹Î± differential privacy
            noise_scale = 1.0 / self.privacy_budget
            local_data = local_data + np.random.laplace(0, noise_scale, local_data.shape)

        # Train local model (simplified)
        from models.lstm import LSTMModel

        local_model = LSTMModel(epochs=epochs, verbose=False)
        X = local_data.drop("cgm", axis=1) if "cgm" in local_data.columns else local_data
        y = local_data["cgm"] if "cgm" in local_data.columns else local_data.iloc[:, 0]

        local_model.fit(X, y)

        # Extract model updates (gradients/weights)
        model_updates = {
            "client_id": self.client_id,
            "model_version": self.global_model_version,
            "updates": self._extract_model_updates(local_model),
            "data_size": len(local_data),
            "privacy_spent": 1.0 / self.privacy_budget,
        }

        return model_updates

    def _extract_model_updates(self, model) -> Dict:
        """Î•Î¾Î±Î³Ï‰Î³Î® model updates Î³Î¹Î± federated averaging."""
        if hasattr(model, "model") and hasattr(model.model, "state_dict"):
            return {name: param.cpu().numpy() for name, param in model.model.state_dict().items()}
        return {}

    async def send_updates(self, model_updates: Dict) -> bool:
        """Î‘Ï€Î¿ÏƒÏ„Î¿Î»Î® updates ÏƒÏ„Î¿Î½ federated server."""
        try:
            # Simulate sending to federated server
            print(f"ğŸ“¡ Sending model updates from client {self.client_id}")
            await asyncio.sleep(0.1)  # Simulate network delay

            # Update contribution score
            self.contribution_score += model_updates["data_size"] * 0.01

            return True
        except Exception as e:
            print(f"âŒ Failed to send updates: {e}")
            return False

    async def receive_global_model(self) -> Optional[Dict]:
        """Î›Î®ÏˆÎ· global model Î±Ï€ÏŒ Ï„Î¿Î½ server."""
        try:
            # Simulate receiving global model
            print(f"ğŸ“¥ Receiving global model update")
            await asyncio.sleep(0.1)

            self.global_model_version += 1

            return {
                "model_version": self.global_model_version,
                "global_weights": {},  # Simulated global weights
                "performance_metrics": {
                    "global_rmse": 15.2,
                    "participating_clients": 150,
                    "rounds_completed": 25,
                },
            }
        except Exception as e:
            print(f"âŒ Failed to receive global model: {e}")
            return None


class DigitalBiomarkerEngine:
    """
    Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· ÎºÎ±Î¹ Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· ÏˆÎ·Ï†Î¹Î±ÎºÏÎ½ Î²Î¹Î¿Î´ÎµÎ¹ÎºÏ„ÏÎ½.

    Î•Î½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Î½Î­Î± patterns ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î­Ï‡Î¿Ï…Î½ ÎºÎ»Î¹Î½Î¹ÎºÎ® ÏƒÎ·Î¼Î±ÏƒÎ¯Î±.
    """

    def __init__(self):
        self.known_biomarkers = {
            "glucose_variability": {
                "description": "ÎœÎµÏ„Î±Î²Î»Î·Ï„ÏŒÏ„Î·Ï„Î± Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚ (CV%)",
                "normal_range": (15, 36),
                "clinical_significance": "Î”ÎµÎ¯ÎºÏ„Î·Ï‚ Î³Î»Ï…ÎºÎ±Î¹Î¼Î¹ÎºÎ¿Ï ÎµÎ»Î­Î³Ï‡Î¿Ï…",
            },
            "dawn_phenomenon": {
                "description": "Î‘ÏÎ¾Î·ÏƒÎ· Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚ Ï„Î¿ Ï€ÏÏ‰Î¯",
                "normal_range": (0, 30),  # mg/dL increase
                "clinical_significance": "Î¦Ï…ÏƒÎ¹Î¿Î»Î¿Î³Î¹ÎºÎ® Î±Î½Ï„Î¯Î´ÏÎ±ÏƒÎ· Î¿ÏÎ¼Î¿Î½ÏÎ½",
            },
            "hypoglycemia_risk_index": {
                "description": "Î”ÎµÎ¯ÎºÏ„Î·Ï‚ ÎºÎ¹Î½Î´ÏÎ½Î¿Ï… Ï…Ï€Î¿Î³Î»Ï…ÎºÎ±Î¹Î¼Î¯Î±Ï‚",
                "normal_range": (0, 1.1),
                "clinical_significance": "Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÎµÏ€Î¹ÎºÎ¯Î½Î´Ï…Î½Ï‰Î½ ÎµÏ€ÎµÎ¹ÏƒÎ¿Î´Î¯Ï‰Î½",
            },
            "meal_response_profile": {
                "description": "Î ÏÎ¿Ï†Î¯Î» Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚ ÏƒÎµ Î³ÎµÏÎ¼Î±Ï„Î±",
                "normal_range": (0.5, 2.0),  # Response factor
                "clinical_significance": "Î•Ï…Î±Î¹ÏƒÎ¸Î·ÏƒÎ¯Î± ÏƒÏ„Î¿Ï…Ï‚ Ï…Î´Î±Ï„Î¬Î½Î¸ÏÎ±ÎºÎµÏ‚",
            },
        }

        self.discovered_biomarkers = []

    def calculate_biomarkers(
        self,
        glucose_data: pd.Series,
        meal_data: Optional[pd.Series] = None,
        insulin_data: Optional[pd.Series] = None,
    ) -> List[DigitalBiomarker]:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î³Î½Ï‰ÏƒÏ„ÏÎ½ Î²Î¹Î¿Î´ÎµÎ¹ÎºÏ„ÏÎ½."""

        biomarkers = []
        timestamp = datetime.now()

        # 1. Glucose Variability (CV%)
        cv = (glucose_data.std() / glucose_data.mean()) * 100
        biomarkers.append(
            DigitalBiomarker(
                name="glucose_variability",
                value=cv,
                timestamp=timestamp,
                trend=self._calculate_trend(cv, [cv]),  # Simplified
                percentile=self._calculate_percentile(cv, (15, 36)),
                clinical_significance=self._assess_clinical_significance("glucose_variability", cv),
            )
        )

        # 2. Dawn Phenomenon
        if len(glucose_data) >= 24:  # At least 24 hours of data
            dawn_effect = self._calculate_dawn_phenomenon(glucose_data)
            biomarkers.append(
                DigitalBiomarker(
                    name="dawn_phenomenon",
                    value=dawn_effect,
                    timestamp=timestamp,
                    trend="stable",
                    percentile=self._calculate_percentile(dawn_effect, (0, 30)),
                    clinical_significance=self._assess_clinical_significance(
                        "dawn_phenomenon", dawn_effect
                    ),
                )
            )

        # 3. Hypoglycemia Risk Index
        hri = self._calculate_hypoglycemia_risk(glucose_data)
        biomarkers.append(
            DigitalBiomarker(
                name="hypoglycemia_risk_index",
                value=hri,
                timestamp=timestamp,
                trend=self._calculate_trend(hri, [hri]),
                percentile=self._calculate_percentile(hri, (0, 1.1)),
                clinical_significance=self._assess_clinical_significance(
                    "hypoglycemia_risk_index", hri
                ),
            )
        )

        # 4. Meal Response Profile
        if meal_data is not None:
            meal_response = self._calculate_meal_response(glucose_data, meal_data)
            biomarkers.append(
                DigitalBiomarker(
                    name="meal_response_profile",
                    value=meal_response,
                    timestamp=timestamp,
                    trend="stable",
                    percentile=self._calculate_percentile(meal_response, (0.5, 2.0)),
                    clinical_significance=self._assess_clinical_significance(
                        "meal_response_profile", meal_response
                    ),
                )
            )

        return biomarkers

    def discover_new_biomarkers(
        self, multi_modal_data: pd.DataFrame, clinical_outcomes: pd.Series
    ) -> List[Dict]:
        """
        Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· Î½Î­Ï‰Î½ ÏˆÎ·Ï†Î¹Î±ÎºÏÎ½ Î²Î¹Î¿Î´ÎµÎ¹ÎºÏ„ÏÎ½ Î¼Î­ÏƒÏ‰ ML.

        Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ feature selection ÎºÎ±Î¹ correlation analysis
        Î³Î¹Î± ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ Î½Î­Ï‰Î½ patterns Î¼Îµ ÎºÎ»Î¹Î½Î¹ÎºÎ® ÏƒÎ·Î¼Î±ÏƒÎ¯Î±.
        """
        from sklearn.feature_selection import SelectKBest, f_regression
        from sklearn.ensemble import RandomForestRegressor

        # Feature selection
        selector = SelectKBest(score_func=f_regression, k=10)
        selected_features = selector.fit_transform(multi_modal_data, clinical_outcomes)
        feature_names = multi_modal_data.columns[selector.get_support()]

        # Random Forest Î³Î¹Î± feature importance
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(selected_features, clinical_outcomes)

        new_biomarkers = []
        for i, (feature, importance) in enumerate(zip(feature_names, rf.feature_importances_)):
            if importance > 0.05:  # Significant features
                new_biomarkers.append(
                    {
                        "name": f"discovered_biomarker_{i}",
                        "feature": feature,
                        "importance": importance,
                        "correlation": np.corrcoef(multi_modal_data[feature], clinical_outcomes)[
                            0, 1
                        ],
                        "potential_clinical_use": self._suggest_clinical_use(feature, importance),
                    }
                )

        self.discovered_biomarkers.extend(new_biomarkers)
        return new_biomarkers

    def _calculate_dawn_phenomenon(self, glucose_data: pd.Series) -> float:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ dawn phenomenon effect."""
        if isinstance(glucose_data.index, pd.DatetimeIndex):
            early_morning = glucose_data.between_time("04:00", "08:00")
            late_night = glucose_data.between_time("02:00", "04:00")

            if len(early_morning) > 0 and len(late_night) > 0:
                return early_morning.mean() - late_night.mean()

        return 0.0

    def _calculate_hypoglycemia_risk(self, glucose_data: pd.Series) -> float:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ¯ÎºÏ„Î· ÎºÎ¹Î½Î´ÏÎ½Î¿Ï… Ï…Ï€Î¿Î³Î»Ï…ÎºÎ±Î¹Î¼Î¯Î±Ï‚."""
        # Simplified LBGI calculation
        log_glucose = np.log(glucose_data / 18.0)  # Convert to mmol/L
        f_bg = 1.509 * (log_glucose**1.084 - 5.381)
        risk_bg = 10 * (f_bg**2)
        lbgi = np.mean(np.where(f_bg < 0, risk_bg, 0))
        return lbgi

    def _calculate_meal_response(self, glucose_data: pd.Series, meal_data: pd.Series) -> float:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ meal response profile."""
        # Find meal events and subsequent glucose response
        meal_responses = []

        for meal_time in meal_data[meal_data > 0].index:
            # Get glucose 2 hours after meal
            end_time = meal_time + pd.Timedelta(hours=2)
            post_meal_glucose = glucose_data.loc[meal_time:end_time]

            if len(post_meal_glucose) > 0:
                peak_glucose = post_meal_glucose.max()
                baseline_glucose = glucose_data.loc[meal_time]
                response = (peak_glucose - baseline_glucose) / meal_data.loc[meal_time]
                meal_responses.append(response)

        return np.mean(meal_responses) if meal_responses else 1.0

    def _calculate_trend(self, current_value: float, historical_values: List[float]) -> str:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ trend Î³Î¹Î± biomarker."""
        if len(historical_values) < 2:
            return "stable"

        recent_avg = np.mean(historical_values[-3:])
        older_avg = np.mean(historical_values[:-3]) if len(historical_values) > 3 else recent_avg

        if recent_avg > older_avg * 1.1:
            return "increasing"
        elif recent_avg < older_avg * 0.9:
            return "decreasing"
        else:
            return "stable"

    def _calculate_percentile(self, value: float, normal_range: Tuple[float, float]) -> float:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ percentile ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ normal range."""
        low, high = normal_range
        if value <= low:
            return 10.0
        elif value >= high:
            return 90.0
        else:
            return 10.0 + 80.0 * (value - low) / (high - low)

    def _assess_clinical_significance(self, biomarker_name: str, value: float) -> str:
        """Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ»Î¹Î½Î¹ÎºÎ®Ï‚ ÏƒÎ·Î¼Î±ÏƒÎ¯Î±Ï‚."""
        if biomarker_name in self.known_biomarkers:
            normal_range = self.known_biomarkers[biomarker_name]["normal_range"]
            low, high = normal_range

            if value < low:
                return "Î§Î±Î¼Î·Î»ÏŒÏ‚ - Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹"
            elif value > high:
                return "Î¥ÏˆÎ·Î»ÏŒÏ‚ - Î¹Î±Ï„ÏÎ¹ÎºÎ® ÏƒÏ…Î¼Î²Î¿Ï…Î»Î® ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹"
            else:
                return "Î•Î½Ï„ÏŒÏ‚ Ï†Ï…ÏƒÎ¹Î¿Î»Î¿Î³Î¹ÎºÏÎ½ Î¿ÏÎ¯Ï‰Î½"

        return "Î†Î³Î½Ï‰ÏƒÏ„Î· ÎºÎ»Î¹Î½Î¹ÎºÎ® ÏƒÎ·Î¼Î±ÏƒÎ¯Î±"

    def _suggest_clinical_use(self, feature: str, importance: float) -> str:
        """Î ÏÏŒÏ„Î±ÏƒÎ· ÎºÎ»Î¹Î½Î¹ÎºÎ®Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ Î³Î¹Î± Î½Î­Î¿ biomarker."""
        use_cases = {
            "high": "Î Î¹Î¸Î±Î½ÏŒÏ‚ Î´ÎµÎ¯ÎºÏ„Î·Ï‚ Î³Î¹Î± personalized therapy",
            "medium": "Î•Î½Î´Î¹Î±Ï†Î­ÏÎ¿Î½ Î³Î¹Î± ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ Î­ÏÎµÏ…Î½Î±",
            "low": "Î”ÎµÏ…Ï„ÎµÏÎµÏÏ‰Î½ Î´ÎµÎ¯ÎºÏ„Î·Ï‚ Î³Î¹Î± ÏƒÏ…Î½Î´Ï…Î±ÏƒÏ„Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·",
        }

        if importance > 0.2:
            level = "high"
        elif importance > 0.1:
            level = "medium"
        else:
            level = "low"

        return use_cases[level]


class ClinicalDecisionSupport:
    """
    Î£ÏÏƒÏ„Î·Î¼Î± Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚ ÎºÎ»Î¹Î½Î¹ÎºÏÎ½ Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½.

    Î Î±ÏÎ­Ï‡ÎµÎ¹ evidence-based recommendations Î³Î¹Î±:
    - Î”Î¿ÏƒÎ¿Î»Î¿Î³Î¯Î± Î¹Î½ÏƒÎ¿Ï…Î»Î¯Î½Î·Ï‚
    - Î”Î¹Î±Ï„ÏÎ¿Ï†Î¹ÎºÎ­Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚
    - Î†ÏƒÎºÎ·ÏƒÎ· ÎºÎ±Î¹ lifestyle
    - Î¤Î¹Î¼Î® ÏƒÏ„ÏŒÏ‡Î¿Ï… Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚
    """

    def __init__(self):
        self.clinical_guidelines = {
            "ada_2024": self._load_ada_guidelines(),
            "easd_2024": self._load_easd_guidelines(),
            "custom": {},
        }

        self.patient_history = {}
        self.recommendation_cache = {}

    def generate_recommendations(
        self, current_glucose: float, predicted_glucose: float, patient_profile: Dict, context: Dict
    ) -> List[Dict]:
        """
        Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± personalized recommendations.

        Args:
            current_glucose: Î¤ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Î³Î»Ï…ÎºÏŒÎ¶Î· (mg/dL)
            predicted_glucose: Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î³Î»Ï…ÎºÏŒÎ¶Î· (mg/dL)
            patient_profile: Î ÏÎ¿Ï†Î¯Î» Î±ÏƒÎ¸ÎµÎ½Î¿ÏÏ‚ (Î·Î»Î¹ÎºÎ¯Î±, Î²Î¬ÏÎ¿Ï‚, HbA1c ÎºÎ»Ï€)
            context: Î¤ÏÎ­Ï‡Î¿Î½ context (ÏÏÎ±, Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„Î±, Î³ÎµÏÎ¼Î±Ï„Î± ÎºÎ»Ï€)
        """
        recommendations = []

        # 1. Insulin Recommendations
        insulin_rec = self._generate_insulin_recommendation(
            current_glucose, predicted_glucose, patient_profile, context
        )
        if insulin_rec:
            recommendations.append(insulin_rec)

        # 2. Nutritional Recommendations
        nutrition_rec = self._generate_nutrition_recommendation(
            current_glucose, predicted_glucose, context
        )
        if nutrition_rec:
            recommendations.append(nutrition_rec)

        # 3. Activity Recommendations
        activity_rec = self._generate_activity_recommendation(
            current_glucose, predicted_glucose, context
        )
        if activity_rec:
            recommendations.append(activity_rec)

        # 4. Monitoring Recommendations
        monitoring_rec = self._generate_monitoring_recommendation(
            current_glucose, predicted_glucose
        )
        if monitoring_rec:
            recommendations.append(monitoring_rec)

        return recommendations

    def _generate_insulin_recommendation(
        self, current_glucose: float, predicted_glucose: float, patient_profile: Dict, context: Dict
    ) -> Optional[Dict]:
        """Î£Ï…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î¹Î½ÏƒÎ¿Ï…Î»Î¯Î½Î·."""

        # Get insulin sensitivity from patient profile
        insulin_sensitivity = patient_profile.get("insulin_sensitivity", 50)  # mg/dL per unit

        # Calculate correction needed
        target_glucose = patient_profile.get("target_glucose", 120)
        correction_needed = predicted_glucose - target_glucose

        if abs(correction_needed) < 20:  # Within acceptable range
            return None

        # Calculate insulin dose
        if correction_needed > 0:  # High glucose
            insulin_units = correction_needed / insulin_sensitivity

            # Safety checks
            max_bolus = patient_profile.get("max_bolus", 10)
            insulin_units = min(insulin_units, max_bolus)

            return {
                "type": "insulin",
                "action": "bolus",
                "dose": round(insulin_units, 1),
                "urgency": "high" if predicted_glucose > 200 else "medium",
                "reasoning": f"Î”Î¹ÏŒÏÎ¸Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î³Î»Ï…ÎºÏŒÎ¶Î· {predicted_glucose:.0f} mg/dL",
                "safety_notes": "Î•Î»Î­Î³Î¾Ï„Îµ ÎºÎµÏ„ÏŒÎ½ÎµÏ‚ Î±Î½ Î³Î»Ï…ÎºÏŒÎ¶Î· >250 mg/dL",
            }

        return None

    def _generate_nutrition_recommendation(
        self, current_glucose: float, predicted_glucose: float, context: Dict
    ) -> Optional[Dict]:
        """Î”Î¹Î±Ï„ÏÎ¿Ï†Î¹ÎºÎ­Ï‚ ÏƒÏ…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚."""

        current_time = context.get("time", datetime.now().hour)

        if predicted_glucose < 70:  # Hypoglycemia risk
            if current_glucose < 60:
                carbs_needed = 20  # Emergency treatment
                urgency = "critical"
            else:
                carbs_needed = 15  # Mild hypoglycemia
                urgency = "high"

            return {
                "type": "nutrition",
                "action": "consume_carbs",
                "amount": f"{carbs_needed}g Î³ÏÎ®Î³Î¿ÏÏ‰Î½ Ï…Î´Î±Ï„Î±Î½Î¸ÏÎ¬ÎºÏ‰Î½",
                "urgency": urgency,
                "suggestions": ["Î§Ï…Î¼ÏŒÏ‚ Ï†ÏÎ¿ÏÏ„Ï‰Î½", "Î–Î¬Ï‡Î±ÏÎ·", "Glucose tablets"],
                "reasoning": f"Î ÏÏŒÎ»Î·ÏˆÎ· Ï…Ï€Î¿Î³Î»Ï…ÎºÎ±Î¹Î¼Î¯Î±Ï‚ (Ï€ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î·: {predicted_glucose:.0f} mg/dL)",
            }

        elif predicted_glucose > 180 and 6 <= current_time <= 10:  # High morning glucose
            return {
                "type": "nutrition",
                "action": "modify_breakfast",
                "urgency": "medium",
                "suggestions": [
                    "ÎœÎµÎ¹ÏÏƒÏ„Îµ Ï„Î¿Ï…Ï‚ Ï…Î´Î±Ï„Î¬Î½Î¸ÏÎ±ÎºÎµÏ‚ ÏƒÏ„Î¿ Ï€ÏÏ‰Î¹Î½ÏŒ",
                    "Î ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï€ÏÏ‰Ï„ÎµÎÎ½ÎµÏ‚",
                    "Î‘Ï€Î¿Ï†ÏÎ³ÎµÏ„Îµ Î³ÏÎ®Î³Î¿ÏÎ¿Ï…Ï‚ Ï…Î´Î±Ï„Î¬Î½Î¸ÏÎ±ÎºÎµÏ‚",
                ],
                "reasoning": "ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï€ÏÏ‰Î¹Î½Î®Ï‚ Ï…Ï€ÎµÏÎ³Î»Ï…ÎºÎ±Î¹Î¼Î¯Î±Ï‚",
            }

        return None

    def _generate_activity_recommendation(
        self, current_glucose: float, predicted_glucose: float, context: Dict
    ) -> Optional[Dict]:
        """Î£Ï…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„Î±."""

        if 120 <= predicted_glucose <= 180:  # Good range for exercise
            return {
                "type": "activity",
                "action": "light_exercise",
                "duration": "15-30 Î»ÎµÏ€Ï„Î¬",
                "urgency": "low",
                "suggestions": ["Î ÎµÏÏ€Î¬Ï„Î·Î¼Î±", "Î•Î»Î±Ï†ÏÎ¹Î­Ï‚ Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚ stretching", "Î‘Î½Î¬Î²Î±ÏƒÎ· ÏƒÎºÎ¬Î»Î±Ï‚"],
                "reasoning": "Î’ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· ÎµÏ…Î±Î¹ÏƒÎ¸Î·ÏƒÎ¯Î±Ï‚ ÏƒÏ„Î·Î½ Î¹Î½ÏƒÎ¿Ï…Î»Î¯Î½Î·",
                "safety_notes": "ÎœÎµÏ„ÏÎ®ÏƒÏ„Îµ Î³Î»Ï…ÎºÏŒÎ¶Î· Ï€ÏÎ¹Î½ ÎºÎ±Î¹ Î¼ÎµÏ„Î¬",
            }

        elif predicted_glucose > 250:  # Too high for exercise
            return {
                "type": "activity",
                "action": "avoid_exercise",
                "urgency": "high",
                "reasoning": "Î Î¿Î»Ï Ï…ÏˆÎ·Î»Î® Î³Î»Ï…ÎºÏŒÎ¶Î· Î³Î¹Î± Î¬ÏƒÎºÎ·ÏƒÎ·",
                "safety_notes": "Î•Î»Î­Î³Î¾Ï„Îµ ÎºÎµÏ„ÏŒÎ½ÎµÏ‚ Ï€ÏÎ¹Î½ Î±Ï€ÏŒ Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„Î±",
            }

        return None

    def _generate_monitoring_recommendation(
        self, current_glucose: float, predicted_glucose: float
    ) -> Optional[Dict]:
        """Î£Ï…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·."""

        if predicted_glucose < 70 or predicted_glucose > 250:
            frequency = "ÎºÎ¬Î¸Îµ 15 Î»ÎµÏ€Ï„Î¬"
            urgency = "high"
        elif predicted_glucose < 90 or predicted_glucose > 200:
            frequency = "ÎºÎ¬Î¸Îµ 30 Î»ÎµÏ€Ï„Î¬"
            urgency = "medium"
        else:
            return None

        return {
            "type": "monitoring",
            "action": "increase_frequency",
            "frequency": frequency,
            "urgency": urgency,
            "reasoning": f"Î£Ï„ÎµÎ½Î® Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î³Î»Ï…ÎºÏŒÎ¶Î· {predicted_glucose:.0f} mg/dL",
            "duration": "Î³Î¹Î± Ï„Î¹Ï‚ ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ 2 ÏÏÎµÏ‚",
        }

    def _load_ada_guidelines(self) -> Dict:
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ADA guidelines."""
        return {
            "target_glucose_range": (70, 180),
            "hba1c_target": 7.0,
            "hypoglycemia_threshold": 70,
            "severe_hypoglycemia_threshold": 54,
            "hyperglycemia_threshold": 250,
        }

    def _load_easd_guidelines(self) -> Dict:
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· EASD guidelines."""
        return {
            "target_glucose_range": (70, 180),
            "hba1c_target": 7.0,
            "time_in_range_target": 70,  # % of time in 70-180 mg/dL
            "below_range_limit": 4,  # % of time below 70 mg/dL
            "above_range_limit": 25,  # % of time above 180 mg/dL
        }


class RealTimeIntelligenceEngine:
    """
    ÎšÎµÎ½Ï„ÏÎ¹ÎºÏŒÏ‚ Real-Time Intelligence Engine Ï€Î¿Ï… ÏƒÏ…Î½Ï„Î¿Î½Î¯Î¶ÎµÎ¹ ÏŒÎ»Î± Ï„Î± Ï…Ï€Î¿ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î±.
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # Initialize sub-engines
        self.edge_engine = EdgeInferenceEngine(
            model_path=config.get("edge_model_path", "models/edge_model.pth"),
            quantization=config.get("quantization", True),
        )

        self.federated_manager = FederatedLearningManager(
            client_id=config.get("client_id", "anonymous"),
            server_url=config.get("federated_server", "federated.digitaltwint1d.org"),
        )

        self.biomarker_engine = DigitalBiomarkerEngine()
        self.clinical_support = ClinicalDecisionSupport()

        # Real-time data streams
        self.data_streams = {
            "cgm": [],
            "meals": [],
            "insulin": [],
            "activity": [],
            "heart_rate": [],
            "sleep": [],
        }

        # Alert system
        self.alert_callbacks = []
        self.active_alerts = []

        # Performance monitoring
        self.performance_metrics = {
            "prediction_accuracy": 0.0,
            "alert_precision": 0.0,
            "user_satisfaction": 0.0,
            "clinical_outcomes": 0.0,
        }

    async def start_real_time_monitoring(self):
        """Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· real-time monitoring ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚."""
        print("ğŸš€ Starting Real-Time Intelligence Engine...")

        # Load edge model
        self.edge_engine.load_model()

        # Start monitoring tasks
        tasks = [
            self._glucose_monitoring_loop(),
            self._biomarker_monitoring_loop(),
            self._federated_learning_loop(),
            self._alert_processing_loop(),
        ]

        await asyncio.gather(*tasks)

    async def _glucose_monitoring_loop(self):
        """ÎšÏÎºÎ»Î¿Ï‚ Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·Ï‚ Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚."""
        while True:
            try:
                # Get latest CGM readings
                if len(self.data_streams["cgm"]) >= 10:
                    latest_readings = [
                        reading["value"] for reading in self.data_streams["cgm"][-10:]
                    ]

                    # Predict next glucose value
                    predicted_glucose, confidence = self.edge_engine.predict_glucose(
                        latest_readings, return_confidence=True
                    )

                    # Check for alerts
                    await self._check_glucose_alerts(
                        current_glucose=latest_readings[-1],
                        predicted_glucose=predicted_glucose,
                        confidence=confidence,
                    )

                    # Adaptive sampling
                    current_glucose = latest_readings[-1]
                    trend = self._calculate_glucose_trend(latest_readings)
                    sampling_interval = self.edge_engine.adaptive_sampling(current_glucose, trend)

                    await asyncio.sleep(sampling_interval)
                else:
                    await asyncio.sleep(60)  # Wait for more data

            except Exception as e:
                print(f"âŒ Error in glucose monitoring: {e}")
                await asyncio.sleep(60)

    async def _biomarker_monitoring_loop(self):
        """ÎšÏÎºÎ»Î¿Ï‚ Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·Ï‚ biomarkers."""
        while True:
            try:
                if len(self.data_streams["cgm"]) >= 100:  # Need sufficient data
                    # Extract glucose data
                    glucose_values = [
                        reading["value"] for reading in self.data_streams["cgm"][-100:]
                    ]
                    glucose_series = pd.Series(glucose_values)

                    # Calculate biomarkers
                    biomarkers = self.biomarker_engine.calculate_biomarkers(glucose_series)

                    # Store and analyze biomarkers
                    for biomarker in biomarkers:
                        await self._process_biomarker(biomarker)

                await asyncio.sleep(3600)  # Check every hour

            except Exception as e:
                print(f"âŒ Error in biomarker monitoring: {e}")
                await asyncio.sleep(3600)

    async def _federated_learning_loop(self):
        """ÎšÏÎºÎ»Î¿Ï‚ federated learning."""
        while True:
            try:
                # Check if we have enough local data for training
                if len(self.data_streams["cgm"]) >= 1000:  # Need substantial data
                    # Prepare local data
                    local_data = self._prepare_federated_data()

                    # Train local model
                    model_updates = self.federated_manager.train_local_model(local_data)

                    # Send updates to server
                    success = await self.federated_manager.send_updates(model_updates)

                    if success:
                        # Receive global model
                        global_model = await self.federated_manager.receive_global_model()
                        if global_model:
                            print(f"âœ… Updated to global model v{global_model['model_version']}")

                await asyncio.sleep(86400)  # Daily federated learning

            except Exception as e:
                print(f"âŒ Error in federated learning: {e}")
                await asyncio.sleep(86400)

    async def _alert_processing_loop(self):
        """ÎšÏÎºÎ»Î¿Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ alerts."""
        while True:
            try:
                # Process pending alerts
                for alert in self.active_alerts.copy():
                    await self._handle_alert(alert)

                await asyncio.sleep(10)  # Check every 10 seconds

            except Exception as e:
                print(f"âŒ Error in alert processing: {e}")
                await asyncio.sleep(10)

    async def _check_glucose_alerts(
        self, current_glucose: float, predicted_glucose: float, confidence: float
    ):
        """ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± glucose alerts."""

        alerts = []

        # Hypoglycemia alerts
        if predicted_glucose < 70:
            severity = "critical" if predicted_glucose < 54 else "high"
            alert = GlucoseAlert(
                timestamp=datetime.now(),
                glucose_value=current_glucose,
                predicted_value=predicted_glucose,
                alert_type="hypoglycemia",
                severity=severity,
                recommendation="Î›Î¬Î²ÎµÏ„Îµ 15g Î³ÏÎ®Î³Î¿ÏÏ‰Î½ Ï…Î´Î±Ï„Î±Î½Î¸ÏÎ¬ÎºÏ‰Î½",
                confidence=confidence,
            )
            alerts.append(alert)

        # Hyperglycemia alerts
        elif predicted_glucose > 250:
            alert = GlucoseAlert(
                timestamp=datetime.now(),
                glucose_value=current_glucose,
                predicted_value=predicted_glucose,
                alert_type="hyperglycemia",
                severity="high",
                recommendation="Î•Î»Î­Î³Î¾Ï„Îµ ÎºÎµÏ„ÏŒÎ½ÎµÏ‚ ÎºÎ±Î¹ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Îµ Î´Î¹Î¿ÏÎ¸Ï‰Ï„Î¹ÎºÎ® Î¹Î½ÏƒÎ¿Ï…Î»Î¯Î½Î·",
                confidence=confidence,
            )
            alerts.append(alert)

        # Rapid change alerts
        if len(self.data_streams["cgm"]) >= 2:
            prev_glucose = self.data_streams["cgm"][-2]["value"]
            rate_of_change = (current_glucose - prev_glucose) / 5  # mg/dL per minute

            if abs(rate_of_change) > 2:  # >2 mg/dL per minute
                alert = GlucoseAlert(
                    timestamp=datetime.now(),
                    glucose_value=current_glucose,
                    predicted_value=predicted_glucose,
                    alert_type="rapid_change",
                    severity="medium",
                    recommendation=f"Î“ÏÎ®Î³Î¿ÏÎ· Î±Î»Î»Î±Î³Î®: {rate_of_change:+.1f} mg/dL/min",
                    confidence=confidence,
                )
                alerts.append(alert)

        # Add alerts to processing queue
        self.active_alerts.extend(alerts)

    def add_glucose_reading(self, glucose_value: float, timestamp: Optional[datetime] = None):
        """Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î½Î­Î±Ï‚ Î¼Î­Ï„ÏÎ·ÏƒÎ·Ï‚ Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚."""
        if timestamp is None:
            timestamp = datetime.now()

        self.data_streams["cgm"].append({"value": glucose_value, "timestamp": timestamp})

        # Keep only recent data (24 hours)
        cutoff_time = timestamp - timedelta(hours=24)
        self.data_streams["cgm"] = [
            reading for reading in self.data_streams["cgm"] if reading["timestamp"] > cutoff_time
        ]

    def register_alert_callback(self, callback: Callable[[GlucoseAlert], None]):
        """Î•Î³Î³ÏÎ±Ï†Î® callback Î³Î¹Î± alerts."""
        self.alert_callbacks.append(callback)

    async def _handle_alert(self, alert: GlucoseAlert):
        """Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ alert."""
        # Notify all registered callbacks
        for callback in self.alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                print(f"âŒ Error in alert callback: {e}")

        # Remove processed alert
        if alert in self.active_alerts:
            self.active_alerts.remove(alert)

    def _calculate_glucose_trend(self, readings: List[float]) -> str:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¬ÏƒÎ·Ï‚ Î³Î»Ï…ÎºÏŒÎ¶Î·Ï‚."""
        if len(readings) < 3:
            return "stable"

        recent_slope = np.polyfit(range(len(readings[-3:])), readings[-3:], 1)[0]

        if recent_slope > 1:
            return "rapidly_increasing"
        elif recent_slope > 0.5:
            return "increasing"
        elif recent_slope < -1:
            return "rapidly_decreasing"
        elif recent_slope < -0.5:
            return "decreasing"
        else:
            return "stable"

    def get_performance_summary(self) -> Dict[str, Any]:
        """Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® performance summary."""
        return {
            "engine_status": "active",
            "total_predictions": self.edge_engine.inference_stats["total_inferences"],
            "avg_prediction_latency": self.edge_engine.inference_stats["avg_latency_ms"],
            "active_alerts": len(self.active_alerts),
            "federated_contribution_score": self.federated_manager.contribution_score,
            "known_biomarkers": len(self.biomarker_engine.known_biomarkers),
            "discovered_biomarkers": len(self.biomarker_engine.discovered_biomarkers),
            "performance_metrics": self.performance_metrics,
        }
